# AI Knowledge Assistant

An intelligent multi-agent system for processing and querying personal knowledge bases. Built with LangChain, LangGraph, and Ollama, it uses Retrieval-Augmented Generation (RAG) to provide contextual and accurate responses.

## ğŸš€ Features

- **Multi-Agent Intelligence**
  - Specialized agents for retrieval, research, writing, and critique
  - State preservation between agent interactions
  - Detailed logging and debugging capabilities
  - Contextual query understanding

- **Modern Web Interface**
  - Full-viewport responsive design
  - Collapsible agent reasoning sections
  - Real-time markdown rendering
  - Interactive chat experience
  - Loading animations and error handling

- **Knowledge Processing**
  - Vector-based document storage with ChromaDB
  - Support for PDF document ingestion
  - Metadata-rich document handling
  - Contextual retrieval system

## ğŸ› ï¸ Technical Stack

### Backend
- Python 3.10+
- LangChain & LangGraph for agent orchestration
- Ollama for local LLM inference
- ChromaDB for vector storage
- FastAPI for API endpoints
- Unstructured for document processing

### Frontend
- HTML5 & Modern CSS
- Vanilla JavaScript
- Marked.js for markdown rendering
- Responsive Flexbox layout

## ğŸš¦ Getting Started

1. **Set Up Python Environment**
```bash
# Create a virtual environment
python3 -m venv .venv

# Activate the virtual environment
# On Windows
.venv\Scripts\activate
# On Unix or MacOS
source .venv/bin/activate

# Upgrade pip
python3 -m pip install --upgrade pip
```

2. **Install Dependencies**
```bash
# Install all required packages
pip install -r requirements.txt
```

3. **Configure Environment**
Create a `.env` file with:
```env
OLLAMA_BASE_URL="http://host.docker.internal:11434"
OLLAMA_MODEL="llama3"
```

4. **Start the Assistant**
```bash
uvicorn api:app --reload
```

5. **Access the Interface**
Open `http://localhost:8000` in your browser to start interacting with your AI Knowledge Assistant.

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ api.py            # FastAPI endpoints
â”œâ”€â”€ main.py           # Agent workflow and chain
â”œâ”€â”€ processor.py      # Document processing
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html    # Web interface
â”œâ”€â”€ docs/            # Knowledge base storage
â””â”€â”€ chroma_db/       # Vector store
```

## ğŸ¤– Agent Workflow

1. **Retriever Agent**
   - Searches knowledge base for relevant information
   - Returns context for further processing

2. **Researcher Agent**
   - Analyzes retrieved context
   - Identifies key information and relationships

3. **Writer Agent**
   - Drafts comprehensive responses
   - Incorporates context and analysis

4. **Critic Agent**
   - Reviews and refines responses
   - Ensures accuracy and completeness

## ğŸ’¡ Usage

1. **Knowledge Base Setup**
   - Place documents in the `docs` directory
   - System automatically processes and indexes them

2. **Interacting with the Assistant**
   - Use the web interface to ask questions
   - View detailed agent reasoning
   - Get contextual, sourced responses

## ğŸ”’ Security Notes

- Environment variables for configuration
- Input validation on all endpoints
- Secure document handling
- Local LLM inference

## ğŸš§ Known Limitations

- Requires pre-existing knowledge base
- Limited agent interaction flexibility
- Performance considerations with large documents

## ğŸ“ Future Enhancements

- Enhanced multi-format document support
- Advanced reasoning capabilities
- Dynamic agent role assignment
- Improved error recovery
- Comprehensive unit testing

## ğŸ¤ Contributing

Feel free to submit issues, fork the repository, and create pull requests for any improvements.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.
# AI-KNOWLEDGE-ASSISTANT
